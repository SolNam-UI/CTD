{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SolNam-UI/CTD/blob/main/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqtNuzbD1_c7"
      },
      "source": [
        "import부"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1JHqfNoZ69AX",
        "outputId": "b0dd8b55-1716-4b25-d594-f3b7a317b3fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting quickdraw\n",
            "  Downloading quickdraw-1.0.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting ColabTurtle\n",
            "  Downloading ColabTurtle-2.1.0.tar.gz (6.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from quickdraw) (2.32.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->quickdraw) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->quickdraw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->quickdraw) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->quickdraw) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading quickdraw-1.0.0-py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: ColabTurtle\n",
            "  Building wheel for ColabTurtle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ColabTurtle: filename=ColabTurtle-2.1.0-py3-none-any.whl size=7643 sha256=6d748558253b460da3eea15dd76df3ea14665b56cdf45bc741259e61d75bde85\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/9e/81/137e7da25129474562d30f8660be599e5c8d79228cb747e5b9\n",
            "Successfully built ColabTurtle\n",
            "Installing collected packages: ColabTurtle, quickdraw\n",
            "Successfully installed ColabTurtle-2.1.0 quickdraw-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install quickdraw tensorflow ColabTurtle Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2un8ZFfgsI6",
        "outputId": "2557d24c-87e9-4daf-8a20-96efaa121005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/파이썬 프로젝트 CTD\n",
            "[Errno 2] No such file or directory: '/content/drive/Mydrive/파이썬 프로젝트 CTD/storage'\n",
            "/content/drive/MyDrive/파이썬 프로젝트 CTD\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/MyDrive/파이썬 프로젝트 CTD\"\n",
        "%run 8409b3feec20f159d8a50b0a811d3bca/draw.py #Colab 환경에서 사용자가 그릴 수 있게 해주는 오픈소스\n",
        "%cd \"/content/drive/Mydrive/파이썬 프로젝트 CTD/storage\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Di-R_2qi9k_G"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import PIL.Image\n",
        "from PIL import Image\n",
        "from quickdraw import QuickDrawDataGroup, QuickDrawData\n",
        "from keras import layers\n",
        "from keras import models\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from ColabTurtle import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main 프로그램부"
      ],
      "metadata": {
        "id": "uvs_AoZA4gP1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2FBG_Njm2gw1",
        "outputId": "571ca98d-4b53-4c2e-f5b2-2dea20514e27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading aircraft carrier drawings\n",
            "load complete\n",
            "loading airplane drawings\n",
            "load complete\n",
            "loading alarm clock drawings\n",
            "load complete\n",
            "loading ambulance drawings\n",
            "load complete\n",
            "loading angel drawings\n",
            "load complete\n",
            "loading animal migration drawings\n",
            "load complete\n",
            "loading ant drawings\n",
            "load complete\n",
            "loading anvil drawings\n",
            "load complete\n",
            "loading apple drawings\n",
            "load complete\n",
            "loading arm drawings\n",
            "load complete\n",
            "loading asparagus drawings\n",
            "load complete\n",
            "loading axe drawings\n",
            "load complete\n",
            "loading backpack drawings\n",
            "load complete\n",
            "loading banana drawings\n",
            "load complete\n",
            "loading bandage drawings\n",
            "load complete\n",
            "loading barn drawings\n",
            "load complete\n",
            "loading baseball bat drawings\n",
            "load complete\n",
            "loading baseball drawings\n",
            "load complete\n",
            "loading basket drawings\n",
            "load complete\n",
            "loading basketball drawings\n",
            "load complete\n",
            "loading bat drawings\n",
            "load complete\n",
            "loading bathtub drawings\n",
            "load complete\n",
            "loading beach drawings\n",
            "load complete\n",
            "loading bear drawings\n",
            "load complete\n",
            "loading beard drawings\n",
            "load complete\n",
            "loading bed drawings\n",
            "load complete\n",
            "loading bee drawings\n",
            "load complete\n",
            "loading belt drawings\n",
            "load complete\n",
            "loading bench drawings\n",
            "load complete\n",
            "loading bicycle drawings\n",
            "load complete\n",
            "loading binoculars drawings\n",
            "load complete\n",
            "loading bird drawings\n",
            "load complete\n",
            "loading birthday cake drawings\n",
            "load complete\n",
            "loading blackberry drawings\n",
            "load complete\n",
            "loading blueberry drawings\n",
            "load complete\n",
            "loading book drawings\n",
            "load complete\n",
            "loading boomerang drawings\n",
            "load complete\n",
            "loading bottlecap drawings\n",
            "load complete\n",
            "loading bowtie drawings\n",
            "load complete\n",
            "loading bracelet drawings\n",
            "load complete\n",
            "loading brain drawings\n",
            "load complete\n",
            "loading bread drawings\n",
            "load complete\n",
            "loading bridge drawings\n",
            "load complete\n",
            "loading broccoli drawings\n",
            "load complete\n",
            "loading broom drawings\n",
            "load complete\n",
            "loading bucket drawings\n",
            "load complete\n",
            "loading bulldozer drawings\n",
            "load complete\n",
            "loading bus drawings\n",
            "load complete\n",
            "loading bush drawings\n",
            "load complete\n",
            "loading butterfly drawings\n",
            "load complete\n",
            "Epoch 1/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 128ms/step - accuracy: 0.0762 - loss: 3.5893 - val_accuracy: 0.0000e+00 - val_loss: 7.2878 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 126ms/step - accuracy: 0.3289 - loss: 2.5133 - val_accuracy: 0.0000e+00 - val_loss: 5.5934 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 130ms/step - accuracy: 0.4822 - loss: 1.8576 - val_accuracy: 0.0000e+00 - val_loss: 5.3944 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 124ms/step - accuracy: 0.5783 - loss: 1.4821 - val_accuracy: 0.0000e+00 - val_loss: 10.1335 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 129ms/step - accuracy: 0.6555 - loss: 1.1627 - val_accuracy: 0.0000e+00 - val_loss: 12.6856 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7271 - loss: 0.9333\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 141ms/step - accuracy: 0.7269 - loss: 0.9339 - val_accuracy: 0.0000e+00 - val_loss: 14.5984 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 128ms/step - accuracy: 0.8024 - loss: 0.6713 - val_accuracy: 0.0000e+00 - val_loss: 10.8815 - learning_rate: 5.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.8523 - loss: 0.5048 - val_accuracy: 0.0000e+00 - val_loss: 20.2696 - learning_rate: 5.0000e-04\n",
            "목표 그림:  broccoli\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<canvas width=280 height=280></canvas>\n",
              "<button>Finish</button>\n",
              "<script>\n",
              "var canvas = document.querySelector('canvas')\n",
              "var ctx = canvas.getContext('2d')\n",
              "ctx.lineWidth = 10\n",
              "var button = document.querySelector('button')\n",
              "var mouse = {x: 0, y: 0}\n",
              "\n",
              "canvas.addEventListener('mousemove', function(e) {\n",
              "  mouse.x = e.pageX - this.offsetLeft\n",
              "  mouse.y = e.pageY - this.offsetTop\n",
              "})\n",
              "canvas.onmousedown = ()=>{\n",
              "  ctx.beginPath()\n",
              "  ctx.moveTo(mouse.x, mouse.y)\n",
              "  canvas.addEventListener('mousemove', onPaint)\n",
              "}\n",
              "canvas.onmouseup = ()=>{\n",
              "  canvas.removeEventListener('mousemove', onPaint)\n",
              "}\n",
              "var onPaint = ()=>{\n",
              "  ctx.lineTo(mouse.x, mouse.y)\n",
              "  ctx.stroke()\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "  button.onclick = ()=>{\n",
              "    resolve(canvas.toDataURL('image/png'))\n",
              "  }\n",
              "})\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
            "정답은:  blackberry입니다.\n",
            "실패!\n"
          ]
        }
      ],
      "source": [
        "# 그림 그리기\n",
        "def inputDrawing():\n",
        "    draw(filename=\"dd.png\", w=280, h=280, line_width=10)\n",
        "\n",
        "    # 사용자가 그린 이미지 전처리\n",
        "    img = Image.open(\"/content/drive/MyDrive/파이썬 프로젝트 CTD/dd.png\").resize((28, 28)).convert(\"L\")\n",
        "    imgTemp = np.array(img) / 255.0\n",
        "    inData = imgTemp.reshape(1, 28, 28, 1)\n",
        "\n",
        "    predict(inData)\n",
        "\n",
        "def predict(inData):\n",
        "    # 예측\n",
        "    prediction = model.predict(inData)\n",
        "    result = trainList[np.argmax(prediction)]\n",
        "    print(\"정답은: \", result + \"입니다.\")\n",
        "    if (result == goalImg) :\n",
        "        print(\"성공!\")\n",
        "    else:\n",
        "        print(\"실패!\")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# 모델 정의\n",
        "model = models.Sequential()\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(50, activation=\"softmax\"))\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# 이미지 리스트 로드\n",
        "trainList = QuickDrawData().drawing_names[:50]\n",
        "\n",
        "# 이미지 학습\n",
        "trainImg, trainLabel = [], []\n",
        "for i, label in enumerate(trainList):\n",
        "    drawings = list(QuickDrawDataGroup(label).drawings)[:100]\n",
        "    for d in drawings:\n",
        "        img = d.image.resize((28, 28)).convert(\"L\")\n",
        "        img_array = np.array(img) / 255.0\n",
        "        trainImg.append(img_array)\n",
        "        trainLabel.append(i)\n",
        "\n",
        "trainImg = np.array(trainImg)\n",
        "trainImg = trainImg.reshape(-1, 28, 28, 1)\n",
        "\n",
        "trainLabel = np.array(trainLabel)\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(trainImg, trainLabel, epochs=10, batch_size=32, validation_split=0.2, callbacks=[reduce_lr, early_stop])\n",
        "\n",
        "# 이미지 리스트에서 그릴 이미지 할당\n",
        "goalImg = trainList[int(random.randrange(0,49))]\n",
        "print(\"목표 그림: \", goalImg)\n",
        "\n",
        "inputDrawing()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}